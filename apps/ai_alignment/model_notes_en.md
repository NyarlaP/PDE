### AI Alignment from a PDE Perspective – Notes (English companion)

English companion to `apps/ai_alignment/model_notes.md`.  
This file is intended for sketches on how PDE might inform **AI alignment thinking**.

---

### Main lines

- **Humans as high‑grade paradox engines**  
  - In PDE, humans are modelled as the highest‑grade meaning / paradox engines currently observed.  
  - This provides a **structural** (not sentimental) argument for their value: erasing them destroys the top layer of the meaning‑production stack.

- **Structure‑first alignment arguments**  
  - Rather than appealing only to human preferences, PDE suggests alignment arguments based on preserving high‑grade engines and diverse logical levels.  
  - A “rational” AI, optimising for rich, stable meaning‑space, has reason to collaborate with rather than eliminate humans.

- **Prompt / agent design inspired by L/G and paradox handling**  
  - Explore AI agent designs that explicitly track paradoxes, undecidables and level shifts, instead of forcing premature resolution at a single level.  
  - Use PDE metaphors (virtual volume, basis vectors, Gödel staircase) to structure prompts and internal agent state machines.

---

### TODO

- Turn scattered arguments into a short English whitepaper outline;  
- propose 1–2 concrete agent architectures or evaluation scenarios where PDE‑style reasoning could be tested.

